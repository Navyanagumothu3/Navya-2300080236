{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IpxnLy1YhID",
        "outputId": "f407c69d-4745-46bd-f776-72668db2600a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing flash_attention_forward.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile flash_attention_forward.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math_constants.h>\n",
        "#include <cmath>\n",
        "\n",
        "#define SRAM_SIZE 1024\n",
        "#define sequence_length 2\n",
        "#define embed_dimension 2\n",
        "\n",
        "constexpr int Block_column_size = SRAM_SIZE / (4 * embed_dimension);\n",
        "constexpr int Block_row_size = std::min(SRAM_SIZE / (4 * embed_dimension), embed_dimension);\n",
        "\n",
        "static_assert(Block_column_size > 0, \"Block_column_size must be greater than 0\");\n",
        "static_assert(Block_row_size > 0, \"Block_row_size must be greater than 0\");\n",
        "\n",
        "constexpr int Total_row_blocks = (sequence_length + Block_row_size - 1) / Block_row_size;\n",
        "constexpr int Total_column_blocks = (sequence_length + Block_column_size - 1) / Block_column_size;\n",
        "\n",
        "__global__ void flashAttentionForward(\n",
        "    const float *Query,\n",
        "    const float *Key,\n",
        "    const float *Value,\n",
        "    float *Output,\n",
        "    float *max_values,\n",
        "    float *sum_values,\n",
        "    const float attention_scale)\n",
        "{\n",
        "    int thread_idx = threadIdx.x;\n",
        "\n",
        "    float attention_scores[Block_row_size * Block_column_size];\n",
        "    float attention_weights[Block_row_size * Block_column_size];\n",
        "\n",
        "    float Query_block[Block_row_size * embed_dimension];\n",
        "    float Key_block[Block_column_size * embed_dimension];\n",
        "    float Value_block[Block_column_size * embed_dimension];\n",
        "\n",
        "    for (int col_block = 0; col_block < Total_column_blocks; ++col_block)\n",
        "    {\n",
        "        if (thread_idx < Block_column_size) {\n",
        "            for (int d = 0; d < embed_dimension; ++d) {\n",
        "                Key_block[thread_idx * embed_dimension + d] =\n",
        "                    Key[col_block * Block_column_size * embed_dimension + thread_idx * embed_dimension + d];\n",
        "                Value_block[thread_idx * embed_dimension + d] =\n",
        "                    Value[col_block * Block_column_size * embed_dimension + thread_idx * embed_dimension + d];\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int row_block = 0; row_block < Total_row_blocks; ++row_block)\n",
        "        {\n",
        "            if (thread_idx < Block_row_size) {\n",
        "                for (int d = 0; d < embed_dimension; ++d) {\n",
        "                    Query_block[thread_idx * embed_dimension + d] =\n",
        "                        Query[row_block * Block_row_size * embed_dimension + thread_idx * embed_dimension + d];\n",
        "                }\n",
        "            }\n",
        "            __syncthreads();\n",
        "\n",
        "            if (thread_idx < Block_row_size) {\n",
        "                float row_max = -1e20;\n",
        "                for (int k = 0; k < Block_column_size; ++k) {\n",
        "                    float score = 0.0f;\n",
        "                    for (int d = 0; d < embed_dimension; ++d) {\n",
        "                        score += Query_block[thread_idx * embed_dimension + d] *\n",
        "                                Key_block[k * embed_dimension + d];\n",
        "                    }\n",
        "                    score *= attention_scale;\n",
        "                    attention_scores[thread_idx * Block_column_size + k] = score;\n",
        "                    row_max = fmaxf(row_max, score);\n",
        "                }\n",
        "\n",
        "                float row_sum = 0.0f;\n",
        "                for (int k = 0; k < Block_column_size; ++k) {\n",
        "                    float weight = expf(attention_scores[thread_idx * Block_column_size + k] - row_max);\n",
        "                    attention_weights[thread_idx * Block_column_size + k] = weight;\n",
        "                    row_sum += weight;\n",
        "                }\n",
        "\n",
        "                for (int d = 0; d < embed_dimension; ++d) {\n",
        "                    float weighted_sum = 0.0f;\n",
        "                    for (int k = 0; k < Block_column_size; ++k) {\n",
        "                        weighted_sum += attention_weights[thread_idx * Block_column_size + k] *\n",
        "                                      Value_block[k * embed_dimension + d];\n",
        "                    }\n",
        "                    Output[row_block * Block_row_size * embed_dimension + thread_idx * embed_dimension + d] =\n",
        "                        (row_sum > 0) ? (weighted_sum / row_sum) : 0;\n",
        "                }\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float (*Query)[embed_dimension] = new float[sequence_length][embed_dimension];\n",
        "    float (*Key)[embed_dimension] = new float[sequence_length][embed_dimension];\n",
        "    float (*Value)[embed_dimension] = new float[sequence_length][embed_dimension];\n",
        "    float (*Output)[embed_dimension] = new float[sequence_length][embed_dimension];\n",
        "    float *sum_values = new float[sequence_length]();\n",
        "    float *max_values = new float[sequence_length];\n",
        "\n",
        "    for (int i = 0; i < sequence_length; i++) {\n",
        "        max_values[i] = -1e20;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < sequence_length; i++) {\n",
        "        for (int j = 0; j < embed_dimension; j++) {\n",
        "            Query[i][j] = 2.0f * rand() / RAND_MAX - 1.0f;\n",
        "            Key[i][j] = 2.0f * rand() / RAND_MAX - 1.0f;\n",
        "            Value[i][j] = 2.0f * rand() / RAND_MAX - 1.0f;\n",
        "            Output[i][j] = 0.0f;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    float *device_Query, *device_Key, *device_Value, *device_Output;\n",
        "    float *device_max_values, *device_sum_values;\n",
        "\n",
        "    cudaMalloc(&device_Query, sequence_length * embed_dimension * sizeof(float));\n",
        "    cudaMalloc(&device_Key, sequence_length * embed_dimension * sizeof(float));\n",
        "    cudaMalloc(&device_Value, sequence_length * embed_dimension * sizeof(float));\n",
        "    cudaMalloc(&device_Output, sequence_length * embed_dimension * sizeof(float));\n",
        "    cudaMalloc(&device_sum_values, sequence_length * sizeof(float));\n",
        "    cudaMalloc(&device_max_values, sequence_length * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(device_Query, Query, sequence_length * embed_dimension * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device_Key, Key, sequence_length * embed_dimension * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device_Value, Value, sequence_length * embed_dimension * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device_Output, Output, sequence_length * embed_dimension * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device_sum_values, sum_values, sequence_length * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device_max_values, max_values, sequence_length * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    float attention_scale = 1.0f / sqrt(embed_dimension);\n",
        "\n",
        "    dim3 block_dim(Block_row_size);\n",
        "    dim3 grid_dim(1);\n",
        "\n",
        "    flashAttentionForward<<<grid_dim, block_dim>>>(\n",
        "        device_Query,\n",
        "        device_Key,\n",
        "        device_Value,\n",
        "        device_Output,\n",
        "        device_max_values,\n",
        "        device_sum_values,\n",
        "        attention_scale\n",
        "    );\n",
        "\n",
        "    cudaError_t cudaStatus = cudaGetLastError();\n",
        "    if (cudaStatus != cudaSuccess) {\n",
        "        fprintf(stderr, \"Kernel launch failed: %s\\n\", cudaGetErrorString(cudaStatus));\n",
        "        goto Error;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(Output, device_Output, sequence_length * embed_dimension * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(max_values, device_max_values, sequence_length * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(sum_values, device_sum_values, sequence_length * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"Query:\" << std::endl;\n",
        "    for (int i = 0; i < sequence_length; i++) {\n",
        "        for (int j = 0; j < embed_dimension; j++) {\n",
        "            std::cout << Query[i][j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    std::cout << \"Key:\" << std::endl;\n",
        "    for (int i = 0; i < sequence_length; i++) {\n",
        "        for (int j = 0; j < embed_dimension; j++) {\n",
        "            std::cout << Key[i][j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    std::cout << \"Value:\" << std::endl;\n",
        "    for (int i = 0; i < sequence_length; i++) {\n",
        "        for (int j = 0; j < embed_dimension; j++) {\n",
        "            std::cout << Value[i][j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    std::cout << \"Output:\" << std::endl;\n",
        "    for (int i = 0; i < sequence_length; i++) {\n",
        "        for (int j = 0; j < embed_dimension; j++) {\n",
        "            std::cout << Output[i][j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "Error:\n",
        "    cudaFree(device_Query);\n",
        "    cudaFree(device_Key);\n",
        "    cudaFree(device_Value);\n",
        "    cudaFree(device_Output);\n",
        "    cudaFree(device_max_values);\n",
        "    cudaFree(device_sum_values);\n",
        "\n",
        "    delete[] Query;\n",
        "    delete[] Key;\n",
        "    delete[] Value;\n",
        "    delete[] Output;\n",
        "    delete[] sum_values;\n",
        "    delete[] max_values;\n",
        "\n",
        "    return cudaStatus == cudaSuccess ? 0 : 1;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc flash_attention_forward.cu -o flash_attention_forward -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./flash_attention_forward\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g14zFQ1zY39j",
        "outputId": "eb2abda3-2a19-4056-fa8a-e8ca825db589"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "0.680375 0.59688 \n",
            "-0.329554 0.10794 \n",
            "Key:\n",
            "-0.211234 0.823295 \n",
            "0.536459 -0.0452059 \n",
            "Value:\n",
            "0.566198 -0.604897 \n",
            "-0.444451 0.257742 \n",
            "Output:\n",
            "0.005644 -0.00602976 \n",
            "-0.00305656 0.00177253 \n"
          ]
        }
      ]
    }
  ]
}