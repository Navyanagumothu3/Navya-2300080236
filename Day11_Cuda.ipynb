{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-QkZz-oeASV",
        "outputId": "c7933bf0-6b4e-49ff-e0e8-f94401c02727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile benchmark.py\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "def get_memory_info():\n",
        "    memory = psutil.virtual_memory()\n",
        "    return memory.used / (1024 ** 3), memory.total / (1024 ** 3)\n",
        "\n",
        "def estimate_memory_usage(N, M):\n",
        "    nnz = (N * M) // 3\n",
        "    memory_gb = (nnz * (2 * 8 + 4)) / (1024 ** 3)\n",
        "    return memory_gb\n",
        "\n",
        "def verify_results(cuda_output_file, torch_output, N):\n",
        "    cuda_results = []\n",
        "    try:\n",
        "        with open(cuda_output_file, 'r', encoding=\"utf-8\") as f:\n",
        "            cuda_results = [float(line.strip()) for line in f if line.strip()]\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CUDA results: {e}\")\n",
        "        return False\n",
        "    torch_results = torch_output.cpu().numpy().flatten().tolist()\n",
        "    if len(cuda_results) != N:\n",
        "        print(f\"CUDA results length mismatch: Expected {N}, Got {len(cuda_results)}\")\n",
        "        return False\n",
        "    if len(torch_results) != N:\n",
        "        print(f\"PyTorch results length mismatch: Expected {N}, Got {len(torch_results)}\")\n",
        "        return False\n",
        "    max_diff = 0\n",
        "    max_relative_diff = 0\n",
        "    tolerance = 1e-5\n",
        "    for i, (cuda_val, torch_val) in enumerate(zip(cuda_results, torch_results)):\n",
        "        abs_diff = abs(cuda_val - torch_val)\n",
        "        max_diff = max(max_diff, abs_diff)\n",
        "        if abs(cuda_val) > 1e-10:\n",
        "            relative_diff = abs_diff / abs(cuda_val)\n",
        "            max_relative_diff = max(max_relative_diff, relative_diff)\n",
        "        if abs_diff > tolerance:\n",
        "            print(f\"Mismatch at index {i}: CUDA = {cuda_val}, PyTorch = {torch_val}\")\n",
        "            print(f\"Absolute difference: {abs_diff}\")\n",
        "            return False\n",
        "    print(f\"Results match within tolerance of {tolerance}\")\n",
        "    print(f\"Maximum absolute difference: {max_diff}\")\n",
        "    print(f\"Maximum relative difference: {max_relative_diff}\")\n",
        "    return True\n",
        "\n",
        "def compile_cuda_program():\n",
        "    compile_command = [\"nvcc\", \"mainy.cu\", \"-o\", \"mainy\"]\n",
        "    subprocess.run(compile_command, check=True)\n",
        "\n",
        "def create_sparse_matrix_and_vector(N, M):\n",
        "    estimated_memory = estimate_memory_usage(N, M)\n",
        "    _, total_memory = get_memory_info()\n",
        "    if estimated_memory > total_memory * 0.7:\n",
        "        raise MemoryError(f\"Estimated memory usage ({estimated_memory:.2f} GB) exceeds safe limit\")\n",
        "    chunk_size = 1000000\n",
        "    indices = []\n",
        "    values = []\n",
        "    for i in range(0, N, chunk_size // M):\n",
        "        end_i = min(i + chunk_size // M, N)\n",
        "        for j in range(M):\n",
        "            for ii in range(i, end_i):\n",
        "                if (ii + j) % 3 == 0:\n",
        "                    indices.append([ii, j])\n",
        "                    values.append(float(ii + j))\n",
        "        if len(indices) > chunk_size:\n",
        "            indices_tensor = torch.tensor(indices, dtype=torch.long).t()\n",
        "            values_tensor = torch.tensor(values, dtype=torch.float32)\n",
        "            if 'final_indices' not in locals():\n",
        "                final_indices = indices_tensor\n",
        "                final_values = values_tensor\n",
        "            else:\n",
        "                final_indices = torch.cat([final_indices, indices_tensor], dim=1)\n",
        "                final_values = torch.cat([final_values, values_tensor])\n",
        "            indices = []\n",
        "            values = []\n",
        "    if indices:\n",
        "        indices_tensor = torch.tensor(indices, dtype=torch.long).t()\n",
        "        values_tensor = torch.tensor(values, dtype=torch.float32)\n",
        "        if 'final_indices' not in locals():\n",
        "            final_indices = indices_tensor\n",
        "            final_values = values_tensor\n",
        "        else:\n",
        "            final_indices = torch.cat([final_indices, indices_tensor], dim=1)\n",
        "            final_values = torch.cat([final_values, values_tensor])\n",
        "    A = torch.sparse_coo_tensor(final_indices, final_values, (N, M))\n",
        "    X = torch.ones(M, 1, dtype=torch.float32)\n",
        "    return A, X\n",
        "\n",
        "def run_cuda_program(N, M):\n",
        "    with open('main.cu', 'r') as file:\n",
        "        content = file.read()\n",
        "    content = content.replace('const int N = 1000;', f'const int N = {N};')\n",
        "    content = content.replace('const int M = 1000;', f'const int M = {M};')\n",
        "    content = content.replace('const int threshold = 700;', f'const int threshold = {int(np.floor(N*0.7))};')\n",
        "    with open('mainy.cu', 'w') as file:\n",
        "        file.write(content)\n",
        "    compile_cuda_program()\n",
        "    result = subprocess.run(['./mainy'], capture_output=True, text=True)\n",
        "    time_line = [line for line in result.stdout.split('\\n') if 'CUDA kernel time:' in line][0]\n",
        "    return float(time_line.split(':')[1].strip().split()[0])\n",
        "\n",
        "def run_torch_program(N, M, num_iterations=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    try:\n",
        "        times = []\n",
        "        for _ in range(num_iterations):\n",
        "            A, X = create_sparse_matrix_and_vector(N, M)\n",
        "            A = A.to(device)\n",
        "            X = X.to(device)\n",
        "            A = A.coalesce()\n",
        "            output_torch = torch.sparse.mm(A, X)\n",
        "            torch.cuda.synchronize()\n",
        "            start = torch.cuda.Event(enable_timing=True)\n",
        "            end = torch.cuda.Event(enable_timing=True)\n",
        "            start.record()\n",
        "            output_torch = torch.sparse.mm(A, X)\n",
        "            end.record()\n",
        "            torch.cuda.synchronize()\n",
        "            times.append(start.elapsed_time(end))\n",
        "        del A, X, output_torch\n",
        "        torch.cuda.empty_cache()\n",
        "        return np.mean(times) / 1000.0\n",
        "    except Exception as e:\n",
        "        print(f\"Error in PyTorch implementation: {str(e)}\")\n",
        "        torch.cuda.empty_cache()\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    sizes = [(10, 10), (1000, 1000), (2000, 2000), (3000, 3000), (4000, 4000),\n",
        "             (5000, 5000), (8000, 8000), (10000, 10000), (15000, 15000)]\n",
        "    results = {\n",
        "        'sizes': sizes,\n",
        "        'cuda_times': [],\n",
        "        'torch_times': [],\n",
        "        'results_match': []\n",
        "    }\n",
        "    for N, M in sizes:\n",
        "        print(f\"\\nTesting size {N}x{M}\")\n",
        "        print(f\"Estimated memory usage: {estimate_memory_usage(N, M):.2f} GB\")\n",
        "        used_mem, total_mem = get_memory_info()\n",
        "        print(f\"Current memory usage: {used_mem:.2f} GB / {total_mem:.2f} GB\")\n",
        "        try:\n",
        "            cuda_time = run_cuda_program(N, M)\n",
        "            results['cuda_times'].append(cuda_time)\n",
        "            print(f\"Custom CUDA implementation time: {cuda_time:.6f} seconds\")\n",
        "        except Exception as e:\n",
        "            print(f\"CUDA implementation failed: {e}\")\n",
        "            results['cuda_times'].append(None)\n",
        "        try:\n",
        "            torch_time = run_torch_program(N, M)\n",
        "            results['torch_times'].append(torch_time)\n",
        "            if torch_time is not None:\n",
        "                print(f\"PyTorch Sparse implementation time: {torch_time:.6f} seconds\")\n",
        "        except Exception as e:\n",
        "            print(f\"PyTorch implementation failed: {e}\")\n",
        "            results['torch_times'].append(None)\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 benchmark.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PedqRwPTe3uI",
        "outputId": "03cd64c5-9df2-4c5e-fde8-0738d0c06ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing size 10x10\n",
            "Estimated memory usage: 0.00 GB\n",
            "Current memory usage: 1.06 GB / 12.67 GB\n",
            "CUDA implementation failed: [Errno 2] No such file or directory: 'main.cu'\n",
            "PyTorch Sparse implementation time: 0.000139 seconds\n",
            "\n",
            "Testing size 1000x1000\n",
            "Estimated memory usage: 0.01 GB\n",
            "Current memory usage: 1.24 GB / 12.67 GB\n",
            "CUDA implementation failed: [Errno 2] No such file or directory: 'main.cu'\n",
            "PyTorch Sparse implementation time: 0.000188 seconds\n",
            "\n",
            "Testing size 2000x2000\n",
            "Estimated memory usage: 0.02 GB\n",
            "Current memory usage: 1.30 GB / 12.67 GB\n",
            "CUDA implementation failed: [Errno 2] No such file or directory: 'main.cu'\n"
          ]
        }
      ]
    }
  ]
}