{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pexvX9TDY05Z",
        "outputId": "229e3a25-bb74-4dee-d74a-4d6da4127067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Matrix_transpose.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile Matrix_transpose.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define WIDTH 4\n",
        "#define HEIGHT 4\n",
        "\n",
        "__global__ void transposeMatrix(const float* input, float* output, int width, int height) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (x < width && y < height) {\n",
        "        int inputIndex = y * width + x;\n",
        "        int outputIndex = x * height + y;\n",
        "        output[outputIndex] = input[inputIndex];\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkCudaError(const char* message) {\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        std::cerr << message << \" - CUDA Error: \" << cudaGetErrorString(error) << std::endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "void printMatrix(const float* matrix, int width, int height, const char* name) {\n",
        "    std::cout << name << \":\\n\";\n",
        "    for (int i = 0; i < height; i++) {\n",
        "        for (int j = 0; j < width; j++) {\n",
        "            std::cout << matrix[i * width + j] << \"\\t\";\n",
        "        }\n",
        "        std::cout << \"\\n\";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int width = WIDTH;\n",
        "    int height = HEIGHT;\n",
        "\n",
        "    size_t size = width * height * sizeof(float);\n",
        "    float* h_input = (float*)malloc(size);\n",
        "    float* h_output = (float*)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < width * height; i++) {\n",
        "        h_input[i] = static_cast<float>(i);\n",
        "    }\n",
        "\n",
        "    float* d_input;\n",
        "    float* d_output;\n",
        "    cudaMalloc((void**)&d_input, size);\n",
        "    cudaMalloc((void**)&d_output, size);\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "    checkCudaError(\"Failed to copy input data to device\");\n",
        "\n",
        "    dim3 blockSize(2, 2);\n",
        "    dim3 gridSize((width + blockSize.x - 1) / blockSize.x,\n",
        "                  (height + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    transposeMatrix<<<gridSize, blockSize>>>(d_input, d_output, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "    checkCudaError(\"Kernel execution failed\");\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost);\n",
        "    checkCudaError(\"Failed to copy output data to host\");\n",
        "\n",
        "    printMatrix(h_input, width, height, \"Input Matrix\");\n",
        "    printMatrix(h_output, height, width, \"Transposed Matrix\");\n",
        "\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < width; i++) {\n",
        "        for (int j = 0; j < height; j++) {\n",
        "            if (h_output[i * height + j] != h_input[j * width + i]) {\n",
        "                success = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << (success ? \"Matrix transposition succeeded!\" : \"Matrix transposition failed!\") << std::endl;\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc Matrix_transpose.cu -o Matrix_transpose -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./Matrix_transpose\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qJc0R0uZXIx",
        "outputId": "6ac39472-ec45-4824-9c1d-69671b49aed8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Matrix:\n",
            "0\t1\t2\t3\t\n",
            "4\t5\t6\t7\t\n",
            "8\t9\t10\t11\t\n",
            "12\t13\t14\t15\t\n",
            "\n",
            "Transposed Matrix:\n",
            "0\t4\t8\t12\t\n",
            "1\t5\t9\t13\t\n",
            "2\t6\t10\t14\t\n",
            "3\t7\t11\t15\t\n",
            "\n",
            "Matrix transposition succeeded!\n"
          ]
        }
      ]
    }
  ]
}